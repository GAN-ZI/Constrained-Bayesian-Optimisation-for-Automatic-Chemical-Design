"""
Script for decoding points in the latent space generated by adding noise to the training data latent points.
"""

from datetime import datetime

import numpy as np
from Constrained_BO.Chemical_Design.ml.autoencoder.latent_space import encode_decode as lasp

from Constrained_BO.utils import save_object


startTime = datetime.now()

# We load the latent features and add noise to them

X_latent = np.loadtxt('latent_features_and_targets/latent_features.txt')
X_latent_with_small_noise = X_latent[0:10000] + \
                            np.random.uniform(-0.1, 0.1, size=(X_latent.shape[0], 56))[0:10000]
m = X_latent_with_small_noise.shape[0]

# We load the decoder to obtain the molecules

preproc = lasp.PreProcessing(dataset='drugs')
enc_dec = lasp.EncoderDecoder()
encoder, decoder = enc_dec.get_functions()
postprocessor = lasp.PostProcessing(enc_dec)

# valid structures

valid_smiles_final = []

# number of molecules decoded to valid structures AND
# NOT methane AND length > 5

num_valid_and_long = []

decode_attempts = 100

# validity labels (1 if more than 20% of decodings are valid and large
# molecules, 0 otherwise)

y_con = np.zeros([X_latent_with_small_noise.shape[0], ])

for i in range(m):

    # decode the noisy latent data points to SMILES strings

    sampler_out = postprocessor.ls_to_smiles([X_latent_with_small_noise[i: (i + 1), :]], decode_attempts,
                                             decode_attempts, )
    rdmols, valid_smiles, all_smiles, output_reps, distances = sampler_out

    valid_sens_smiles = [x for x in valid_smiles if len(x) > 5]
    num_sensible_and_long = sum([all_smiles.count(x) for x in valid_sens_smiles])

    num_valid_and_long.append(num_sensible_and_long)

    valid_smiles_final.append(valid_sens_smiles)

    if num_sensible_and_long > decode_attempts / 5.0:
        y_con[i] = 1.0
    else:
        y_con[i] = 0.0

    print(i)

save_object(y_con, "Small_Noise/y.dat")
save_object(X_latent_with_small_noise, "Small_Noise/X.dat")

print (datetime.now() - startTime)
